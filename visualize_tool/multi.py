import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
from typing import List

max_mse=10000
# --------------------------
# åŸºç¡€é…ç½®ï¼šç¦ç”¨å¼¹çª—+ç»Ÿä¸€æ ·å¼
# --------------------------
plt.switch_backend('Agg')  # éäº¤äº’å¼åç«¯ï¼Œä»…ä¿å­˜å›¾ç‰‡ä¸å¼¹çª—
plt.rcParams.update({
    "axes.unicode_minus": False,  # ä¿®å¤è´Ÿå·æ˜¾ç¤º
    "font.size": 10,              # ç»Ÿä¸€åŸºç¡€å­—ä½“å¤§å°
    "figure.facecolor": "white",  # å›¾è¡¨èƒŒæ™¯ä¸ºç™½è‰²ï¼ˆé¿å…ä¿å­˜åé€æ˜ï¼‰
    "savefig.dpi": 300            # é»˜è®¤é«˜åˆ†è¾¨ç‡ä¿å­˜ï¼ˆ300dpiï¼‰
})


# --------------------------
# å·¥å…·å‡½æ•°ï¼šè·¯å¾„å¤„ç†ä¸æ–‡ä»¶å¤¹åˆ›å»º
# --------------------------
def get_valid_csv_path() -> str:
    """ä»æ§åˆ¶å°è·å–å¹¶éªŒè¯CSVè·¯å¾„æœ‰æ•ˆæ€§ï¼Œè¿”å›ç»å¯¹è·¯å¾„"""
    while True:
        input_path = input("\nè¯·è¾“å…¥é¢„å¤„ç†ç»“æœCSVæ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼ˆä¾‹ï¼š/data/results.csvï¼‰ï¼š").strip()
        full_path = os.path.abspath(input_path)  # ç›¸å¯¹è·¯å¾„è½¬ç»å¯¹è·¯å¾„
        
        # å¤šç»´åº¦éªŒè¯
        if not os.path.exists(full_path):
            print(f"âŒ é”™è¯¯ï¼šè·¯å¾„ '{full_path}' ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")
        elif not os.path.isfile(full_path):
            print(f"âŒ é”™è¯¯ï¼š'{full_path}' ä¸æ˜¯æ–‡ä»¶ï¼Œè¯·è¾“å…¥æœ‰æ•ˆæ–‡ä»¶è·¯å¾„ï¼")
        elif not full_path.endswith(".csv"):
            print(f"âŒ é”™è¯¯ï¼š'{full_path}' ä¸æ˜¯CSVæ–‡ä»¶ï¼Œè¯·è¾“å…¥ .csv æ ¼å¼è·¯å¾„ï¼")
        else:
            print(f"âœ… éªŒè¯é€šè¿‡ï¼CSVè·¯å¾„ï¼š{full_path}")
            return full_path


def create_plot_dir(csv_path: str, dir_name: str = "preprocessing_analysis_plots") -> str:
    """åœ¨CSVåŒçº§ç›®å½•åˆ›å»ºå›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œè¿”å›æ–‡ä»¶å¤¹ç»å¯¹è·¯å¾„"""
    csv_dir = os.path.dirname(csv_path)
    plot_dir = os.path.join(csv_dir, dir_name)
    new_dir = os.path.join(plot_dir,csv_path.split('/')[-1].replace('.csv',''))
    # è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå·²å­˜åœ¨åˆ™è·³è¿‡ï¼‰
    os.makedirs(plot_dir, exist_ok=True)
    os.makedirs(new_dir, exist_ok=True)

    print(f"\nğŸ“‚ å›¾ç‰‡å­˜å‚¨æ–‡ä»¶å¤¹ï¼š{new_dir}")
    return new_dir


# --------------------------
# æ ¸å¿ƒå‡½æ•°1ï¼šæ•°æ®åŠ è½½ä¸è§£æ
# --------------------------
def load_parse_data(csv_path: str) -> pd.DataFrame:
    """åŠ è½½CSVå¹¶è§£æconfigåˆ—çš„JSONå‚æ•°ï¼Œè¿”å›å®Œæ•´DataFrame"""
    print("\nğŸ”„ æ­¥éª¤1/7ï¼šåŠ è½½å¹¶è§£ææ•°æ®...")
    try:
        # åŠ è½½åŸå§‹CSV
        df = pd.read_csv(csv_path)
        
        # éªŒè¯å¿…è¦åˆ—ï¼ˆé¿å…åç»­æŠ¥é”™ï¼‰
        required_cols = ["trial", "config", "mse", "mae", "smape", "time_sec"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"CSVç¼ºå°‘å¿…è¦åˆ—ï¼š{', '.join(missing_cols)}")
        
        # å®‰å…¨è§£æconfigåˆ—ï¼ˆå¤„ç†CSVä¸­å¯èƒ½çš„è½¬ä¹‰ç¬¦ï¼Œå¦‚""â†’"ï¼‰
        def safe_json_load(x):
            try:
                # å¤„ç†CSVä¸­configåˆ—çš„å¼•å·è½¬ä¹‰é—®é¢˜
                clean_x = x.strip('"').replace('""', '"')
                return json.loads(clean_x)
            except json.JSONDecodeError:
                raise ValueError(f"configåˆ—JSONæ ¼å¼é”™è¯¯ï¼Œé”™è¯¯æ•°æ®ç‰‡æ®µï¼š{x[:50]}...")
        
        # è§£æconfigä¸ºDataFrameå¹¶åˆå¹¶
        config_df = pd.DataFrame(list(df["config"].apply(safe_json_load)))
        result_df = pd.concat([df.drop("config", axis=1), config_df], axis=1)
        
        print(f"âœ… æ•°æ®è§£æå®Œæˆï¼å…± {len(result_df)} ç»„å®éªŒï¼Œå‚æ•°åˆ—è¡¨ï¼š{config_df.columns.tolist()}")
        return result_df
    
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")
        exit(1)  # æ•°æ®é”™è¯¯æ— æ³•ç»§ç»­ï¼Œç»ˆæ­¢ç¨‹åº


# --------------------------
# æ ¸å¿ƒå‡½æ•°2ï¼šå¯è§†åŒ–å›¾è¡¨ç”Ÿæˆï¼ˆå…±6ç±»å›¾ï¼‰
# --------------------------
def plot_top_performers(df: pd.DataFrame, plot_dir: str, metric: str = "mse", top_n: int = 10) -> None:
    """ç”ŸæˆTop Næœ€ä¼˜ç»„åˆæŸ±çŠ¶å›¾"""
    print(f"\nğŸ¯ æ­¥éª¤2/7ï¼šç”ŸæˆTop {top_n} æœ€ä¼˜ç»„åˆå›¾ï¼ˆæŒ‰{metric.upper()}æ’åºï¼‰...")
    try:
        # æ’åºå¹¶æå–å…³é”®å‚æ•°
        sorted_df = df.sort_values(metric).head(top_n).copy()
        key_params = ["trimmer_seq_len", "normalizer_method", "denoiser_method"]  # å¯è‡ªå®šä¹‰å…³é”®å‚æ•°
        sorted_df["label"] = sorted_df.apply(
            lambda x: f"Trial {x['trial']}\n" + "\n".join([f"{p}: {x[p]}" for p in key_params]),
            axis=1
        )
        
        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=(12, 6))
        bars = ax.bar(sorted_df["label"], sorted_df[metric], color="#4CAF50", alpha=0.8, edgecolor="#2E7D32")
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width()/2, height,
                f"{height:.6f}", ha="center", va="bottom", fontsize=8
            )
        
        # æ ·å¼é…ç½®
        ax.set_title(f"Top {top_n} Preprocessing Combinations (Sorted by {metric.upper()})", fontsize=12, pad=20)
        ax.set_xlabel("Trial ID & Key Parameters", fontsize=10)
        ax.set_ylabel(f"{metric.upper()} (Lower = Better)", fontsize=10)
        ax.tick_params(axis="x", rotation=45, labelsize=8)
        ax.grid(axis="y", alpha=0.3, linestyle="--")
        
        # ä¿å­˜å›¾ç‰‡
        save_path = os.path.join(plot_dir, f"top_{top_n}_by_{metric}.png")
        plt.tight_layout()  # é˜²æ­¢æ ‡ç­¾æˆªæ–­
        plt.savefig(save_path, bbox_inches="tight")
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”ŸæˆTop Nå›¾å¤±è´¥ï¼š{str(e)}")


def plot_single_param_impact(df: pd.DataFrame, plot_dir: str, param: str, metric: str = "mse") -> None:
    """ç”Ÿæˆå•ä¸ªå‚æ•°å¯¹æ€§èƒ½çš„å½±å“æŠ˜çº¿å›¾ï¼ˆå¸¦è¯¯å·®æ¡ï¼‰"""
    print(f"\nğŸ“Š æ­¥éª¤3/7ï¼šç”Ÿæˆå‚æ•° '{param}' å½±å“å›¾...")
    try:
        # åˆ†ç»„è®¡ç®—ç»Ÿè®¡é‡
        grouped = df.groupby(param)[metric].agg(["mean", "std", "count"]).reset_index()
        grouped = grouped[grouped["count"] >= 1]  # è¿‡æ»¤æ— æ•°æ®åˆ†ç»„
        
        if len(grouped) < 2:
            print(f"âš ï¸ å‚æ•° '{param}' å”¯ä¸€å€¼è¿‡å°‘ï¼ˆä»…{len(grouped)}ä¸ªï¼‰ï¼Œè·³è¿‡ç»˜å›¾ï¼")
            return
        
        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.errorbar(
            x=grouped[param], y=grouped["mean"], yerr=grouped["std"],
            fmt="o-", color="#FF5722", ecolor="#BDBDBD", capsize=5,
            markersize=6, linewidth=2
        )
        
        # æ·»åŠ æ ·æœ¬é‡æ ‡ç­¾
        for _, row in grouped.iterrows():
            ax.text(
                row[param], row["mean"] + row["std"] + 0.0001,
                f"n={int(row['count'])}", ha="center", va="bottom", fontsize=8
            )
        
        # æ ·å¼é…ç½®
        ax.set_title(f"Impact of {param} on {metric.upper()}", fontsize=12, pad=20)
        ax.set_xlabel(param, fontsize=10)
        ax.set_ylabel(f"Average {metric.upper()}", fontsize=10)
        ax.grid(alpha=0.3, linestyle="--")
        
        # ä¿å­˜
        save_path = os.path.join(plot_dir, f"param_impact_{param}_vs_{metric}.png")
        plt.tight_layout()
        plt.savefig(save_path, bbox_inches="tight")
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆ'{param}'å½±å“å›¾å¤±è´¥ï¼š{str(e)}")


def plot_param_interaction(df: pd.DataFrame, plot_dir: str, param1: str, param2: str, metric: str = "mse") -> None:
    """ç”Ÿæˆä¸¤ä¸ªå‚æ•°äº¤äº’å½±å“çš„çƒ­åŠ›å›¾"""
    print(f"\nğŸ”— æ­¥éª¤4/7ï¼šç”Ÿæˆå‚æ•° '{param1}' ä¸ '{param2}' äº¤äº’å›¾...")
    try:
        # åˆ†ç»„å¹¶è½¬ä¸ºçƒ­åŠ›å›¾æ ¼å¼
        interaction_data = df.groupby([param1, param2])[metric].mean().reset_index()
        pivot_data = interaction_data.pivot(index=param2, columns=param1, values=metric)
        
        if pivot_data.empty:
            print(f"âš ï¸ æ—  '{param1}-{param2}' äº¤äº’æ•°æ®ï¼Œè·³è¿‡ç»˜å›¾ï¼")
            return
        
        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(
            pivot_data, annot=True, fmt=".6f", cmap="YlGnBu_r",  # åå‘è‰²ï¼šå€¼è¶Šä½é¢œè‰²è¶Šæ·±
            cbar_kws={"label": f"Average {metric.upper()}", "shrink": 0.8},
            annot_kws={"fontsize": 8}, linewidths=0.5, ax=ax
        )
        
        # æ ·å¼é…ç½®
        ax.set_title(f"Interaction Between {param1} & {param2}\n(Metric: {metric.upper()})", fontsize=12, pad=20)
        ax.set_xlabel(param1, fontsize=10)
        ax.set_ylabel(param2, fontsize=10)
        
        # ä¿å­˜
        save_path = os.path.join(plot_dir, f"param_interaction_{param1}_vs_{param2}_{metric}.png")
        plt.tight_layout()
        plt.savefig(save_path, bbox_inches="tight")
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆäº¤äº’å›¾å¤±è´¥ï¼š{str(e)}")


def plot_metric_corr(df: pd.DataFrame, plot_dir: str) -> None:
    """ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡ç›¸å…³æ€§çŸ©é˜µçƒ­åŠ›å›¾"""
    print(f"\nğŸ“ˆ æ­¥éª¤5/7ï¼šç”ŸæˆæŒ‡æ ‡ç›¸å…³æ€§çŸ©é˜µå›¾...")
    try:
        # é€‰æ‹©æŒ‡æ ‡åˆ—
        metrics = ["mse", "mae", "smape", "time_sec"]
        valid_metrics = [col for col in metrics if col in df.columns]
        
        if len(valid_metrics) < 2:
            print(f"âš ï¸ æœ‰æ•ˆæŒ‡æ ‡è¿‡å°‘ï¼ˆä»…{valid_metrics}ï¼‰ï¼Œè·³è¿‡ç»˜å›¾ï¼")
            return
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_matrix = df[valid_metrics].corr()
        
        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            corr_matrix, annot=True, fmt=".3f", cmap="coolwarm",
            vmin=-1, vmax=1, cbar_kws={"label": "Pearson Correlation"},
            annot_kws={"fontsize": 10}, linewidths=0.5, ax=ax
        )
        
        # æ ·å¼é…ç½®
        ax.set_title("Correlation Matrix: Metrics & Inference Time", fontsize=12, pad=20)
        
        # ä¿å­˜
        save_path = os.path.join(plot_dir, "metric_correlation_matrix.png")
        plt.tight_layout()
        plt.savefig(save_path, bbox_inches="tight")
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆç›¸å…³æ€§çŸ©é˜µå›¾å¤±è´¥ï¼š{str(e)}")


def plot_time_vs_metric(df: pd.DataFrame, plot_dir: str, metric: str = "mse") -> None:
    """ç”Ÿæˆæ¨ç†æ—¶é—´ä¸æ€§èƒ½çš„æƒè¡¡æ•£ç‚¹å›¾"""
    print(f"\nâš–ï¸ æ­¥éª¤6/7ï¼šç”Ÿæˆæ¨ç†æ—¶é—´ä¸{metric.upper()}æƒè¡¡å›¾...")
    try:
        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=(10, 5))
        scatter = ax.scatter(
            df["time_sec"], df[metric],
            c=df[metric], cmap="viridis_r",  # é¢œè‰²æ˜ å°„ï¼šæ€§èƒ½è¶Šå¥½é¢œè‰²è¶Šæ·±
            alpha=0.6, s=50, edgecolors="gray", linewidths=0.5
        )
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label(f"{metric.upper()} (Lower = Better)", fontsize=10)
        
        # æ ·å¼é…ç½®
        ax.set_title(f"Inference Time vs. {metric.upper()} (Trade-off Analysis)", fontsize=12, pad=20)
        ax.set_xlabel("Inference Time (sec)", fontsize=10)
        ax.set_ylabel(metric.upper(), fontsize=10)
        ax.grid(alpha=0.3, linestyle="--")
        
        # ä¿å­˜
        save_path = os.path.join(plot_dir, f"time_vs_{metric}_tradeoff.png")
        plt.tight_layout()
        plt.savefig(save_path, bbox_inches="tight")
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆæƒè¡¡å›¾å¤±è´¥ï¼š{str(e)}")


# --------------------------
# æ ¸å¿ƒå‡½æ•°3ï¼šæœ€ä¼˜å‚æ•°æ±‡æ€»ï¼ˆæ§åˆ¶å°è¾“å‡ºï¼‰
# --------------------------
def print_optimal_params(df: pd.DataFrame, metric: str = "mse", top_n: int = 5) -> None:
    """åœ¨æ§åˆ¶å°è¾“å‡ºTop Næœ€ä¼˜é¢„å¤„ç†ç»„åˆæ±‡æ€»"""
    print(f"\nğŸ† æ­¥éª¤7/7ï¼šè¾“å‡ºTop {top_n} æœ€ä¼˜é¢„å¤„ç†ç»„åˆ...")
    try:
        # æ’åºå¹¶ç­›é€‰å±•ç¤ºåˆ—
        top_df = df.sort_values(metric).head(top_n).copy()
        core_params = [col for col in df.columns if col not in ["trial", "mse", "mae", "smape", "time_sec"]]
        display_df = top_df[["trial", metric] + core_params].reset_index(drop=True)
        display_df.index += 1  # ç´¢å¼•ä»1å¼€å§‹ï¼Œæ›´æ˜“è¯»
        
        # æ‰“å°æ±‡æ€»è¡¨
        print(f"\nã€Top {top_n} Optimal Combinations (Sorted by {metric.upper()})ã€‘")
        print("-" * 150)
        pd.set_option('display.max_columns', None)  # æ˜¾ç¤ºæ‰€æœ‰åˆ—
        pd.set_option('display.width', 150)         # é€‚é…å®½å±
        pd.set_option('display.max_colwidth', 20)   # é™åˆ¶åˆ—å®½
        print(display_df)
        
        # ç»Ÿè®¡æœ€ä¼˜å‚æ•°å‡ºç°é¢‘ç‡ï¼ˆè¾…åŠ©å†³ç­–ï¼‰
        print(f"\nã€Parameter Frequency in Top {top_n}ã€‘")
        print("-" * 80)
        for param in core_params[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªå…³é”®å‚æ•°ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
            freq = top_df[param].value_counts().head(2)
            print(f"{param:<20} {freq.to_dict()}")
        
        print(f"\nğŸ’¡ å»ºè®®ï¼šä¼˜å…ˆé€‰æ‹©Top 3ç»„åˆçš„å‚æ•°äº¤é›†ï¼Œå¹³è¡¡æ€§èƒ½ä¸ç¨³å®šæ€§ï¼")
    
    except Exception as e:
        print(f"âš ï¸ è¾“å‡ºæœ€ä¼˜å‚æ•°å¤±è´¥ï¼š{str(e)}")

# ä¿®å¤åçš„æ“ä½œç»„åˆä¸åŸºå‡†å¯¹æ¯”å›¾å‡½æ•°
def plot_operation_vs_baseline(df: pd.DataFrame, plot_dir: str, metric: str = "mse") -> None:
    """
    ç”Ÿæˆå„æ“ä½œç»„åˆä¸ä¸åšæ“ä½œï¼ˆåŸºå‡†ï¼‰çš„æ€§èƒ½å¯¹æ¯”å›¾
    å·²ä¿®å¤'trimmer_method'ä¸å­˜åœ¨çš„é”™è¯¯
    """
    print(f"\nğŸ“Š ç”Ÿæˆæ“ä½œç»„åˆä¸åŸºå‡†ï¼ˆä¸åšæ“ä½œï¼‰çš„{metric.upper()}å¯¹æ¯”å›¾...")
    try:
        # 1. å®šä¹‰"ä¸åšæ“ä½œ"çš„åŸºå‡†æ¡ä»¶ï¼ˆä½¿ç”¨æ­£ç¡®çš„å‚æ•°åï¼‰
        baseline_mask = (
            (df["denoiser_method"] == "none") & 
            (df["normalizer_method"] == "none") &
            (df["warper_method"] == "none") &
            (df["differentiator_n"] == 0) &
            (df["clip_factor"] == "none")
        )
        baseline_data = df[baseline_mask]
        
        if len(baseline_data) == 0:
            print("âš ï¸ æœªæ‰¾åˆ°å®Œå…¨'ä¸åšæ“ä½œ'çš„åŸºå‡†æ•°æ®ï¼Œä½¿ç”¨æœ€ç®€åŒ–æ“ä½œä½œä¸ºåŸºå‡†")
            baseline_mask = (df["denoiser_method"] == "none") & (df["normalizer_method"] == "none")
            baseline_data = df[baseline_mask]
            
            if len(baseline_data) == 0:
                raise ValueError("æ— æ³•æ‰¾åˆ°åˆé€‚çš„åŸºå‡†æ•°æ®ï¼ˆä¸åšæ“ä½œçš„è®°å½•ï¼‰")
        
        # å–åŸºå‡†çš„å¹³å‡å€¼ä½œä¸ºæ¯”è¾ƒæ ‡å‡†
        baseline_value = baseline_data[metric].mean()
        print(f"ğŸ“Œ åŸºå‡†{metric.upper()}å€¼: {baseline_value:.8f} (åŸºäº{len(baseline_data)}æ¡åŸºå‡†æ•°æ®)")
        
        # 2. æå–æ“ä½œç»„åˆçš„æ•°æ®
        operation_mask = ~baseline_mask
        operation_data = df[operation_mask].copy()
        
        # åˆ›å»ºç»„åˆæ ‡è¯†ï¼ˆä½¿ç”¨æ­£ç¡®çš„trimmer_seq_lenå‚æ•°ï¼Œç§»é™¤trimmer_methodï¼‰
        operation_data["combination"] = operation_data.apply(
            lambda x: f"{x['denoiser_method']}+{x['normalizer_method']}+{x['warper_method']}+{x['trimmer_seq_len']}",
            axis=1
        )
        
        # æŒ‰ç»„åˆåˆ†ç»„å–å¹³å‡
        grouped_ops = operation_data.groupby("combination")[metric].mean().reset_index()
        grouped_ops = grouped_ops.sort_values(metric)
        
        # 3. è®¡ç®—ä¸åŸºå‡†çš„å·®å¼‚ç™¾åˆ†æ¯”
        grouped_ops["diff_from_baseline"] = (grouped_ops[metric] - baseline_value) / baseline_value * 100
        
        # 4. ç»˜å›¾
        fig_width = min(14, 2 + len(grouped_ops) * 0.8)
        fig, ax = plt.subplots(figsize=(fig_width, 8))
        
        # ç»˜åˆ¶æ“ä½œç»„åˆæŸ±å½¢
        bars = ax.bar(
            grouped_ops["combination"], 
            grouped_ops[metric], 
            color=np.where(grouped_ops["diff_from_baseline"] < 0, "#4CAF50", "#F44336"),
            alpha=0.8, 
            edgecolor="black"
        )
        
        # ç»˜åˆ¶åŸºå‡†çº¿
        ax.axhline(y=baseline_value, color="#2196F3", linestyle="--", linewidth=2, label="Baseline (No Operation)")
        
        # æ·»åŠ å·®å¼‚ç™¾åˆ†æ¯”æ ‡ç­¾
        for i, bar in enumerate(bars):
            height = bar.get_height()
            diff = grouped_ops["diff_from_baseline"].iloc[i]
            label = f"{diff:+.1f}%"
            
            va = "bottom" if height > baseline_value else "top"
            ax.text(
                bar.get_x() + bar.get_width()/2, height,
                label, ha="center", va=va,
                color="black", fontweight="bold", rotation=90
            )
        
        # æ ·å¼é…ç½®
        ax.set_title(f"Performance Comparison: Operations vs. Baseline ({metric.upper()})", fontsize=14, pad=20)
        ax.set_xlabel("Operation Combinations (denoiser+normalizer+warper+trimmer_len)", fontsize=12)
        ax.set_ylabel(f"{metric.upper()} (Lower = Better)", fontsize=12)
        ax.tick_params(axis="x", rotation=90, labelsize=10)
        ax.grid(axis="y", alpha=0.3, linestyle="--")
        ax.legend(fontsize=10)
        
        # ä¿å­˜å›¾ç‰‡
        save_path = os.path.join(plot_dir, f"operations_vs_baseline_{metric}.png")
        plt.tight_layout()
        plt.savefig(save_path, bbox_inches="tight")
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆæ“ä½œå¯¹æ¯”å›¾å¤±è´¥ï¼š{str(e)}")

from math import pi
# ä¿®å¤åçš„é›·è¾¾å›¾å¯¹æ¯”å‡½æ•°

def get_diverse_combinations(df: pd.DataFrame, max_combinations: int = 16) -> pd.DataFrame:
    """
    ä»æ‰€æœ‰ç»„åˆä¸­é€‰æ‹©æœ€å…·å¤šæ ·æ€§çš„ç»„åˆï¼Œç¡®ä¿è¦†ç›–ä¸åŒç±»å‹çš„é¢„å¤„ç†æ–¹æ³•
    
    å‚æ•°:
        df: åŒ…å«æ‰€æœ‰å®éªŒæ•°æ®çš„DataFrame
        max_combinations: æœ€å¤§è¿”å›ç»„åˆæ•°é‡
    è¿”å›:
        å…·æœ‰ä»£è¡¨æ€§çš„ç»„åˆDataFrame
    """
    # åˆ›å»ºç»„åˆæ ‡è¯†
    df["combination"] = df.apply(
        lambda x: f"{x['denoiser_method']}+{x['normalizer_method']}+{x['warper_method']}+{x['trimmer_seq_len']}",
        axis=1
    )
    
    # æŒ‰ç»„åˆåˆ†ç»„è®¡ç®—å„æŒ‡æ ‡å¹³å‡å€¼
    grouped_ops = df.groupby("combination").agg({
        "mse": "mean",
        "mae": "mean",
        "smape": "mean",
        "denoiser_method": "first",
        "normalizer_method": "first",
        "warper_method": "first",
        "trimmer_seq_len": "first"
    }).reset_index()
    
    # å¦‚æœæ€»ç»„åˆæ•°å°äºç­‰äºmax_combinationsï¼Œç›´æ¥è¿”å›æ‰€æœ‰
    if len(grouped_ops) <= max_combinations:
        return grouped_ops
    
    # å…³é”®å‚æ•°ç±»åˆ«
    key_params = [
        "denoiser_method", 
        "normalizer_method", 
        "warper_method"
    ]
    
    # ä¸ºæ¯ä¸ªå…³é”®å‚æ•°è®¡ç®—å…¶ä¸åŒå–å€¼çš„è¦†ç›–ç‡
    def calculate_coverage(selected, all_values, param):
        """è®¡ç®—ç‰¹å®šå‚æ•°çš„è¦†ç›–ç‡"""
        unique_vals = set(all_values[param].unique())
        selected_vals = set(selected[param].unique())
        return len(selected_vals) / len(unique_vals) if unique_vals else 1.0
    
    # è´ªå¿ƒç®—æ³•é€‰æ‹©æœ€å…·å¤šæ ·æ€§çš„ç»„åˆ
    selected = pd.DataFrame(columns=grouped_ops.columns)
    
    # é¦–å…ˆç¡®ä¿åŒ…å«åŸºå‡†ç»„åˆï¼ˆæ— é¢„å¤„ç†ï¼‰
    baseline_mask = (
        (grouped_ops["denoiser_method"] == "none") & 
        (grouped_ops["normalizer_method"] == "none") &
        (grouped_ops["warper_method"] == "none")
    )
    if grouped_ops[baseline_mask].any().any():
        baseline = grouped_ops[baseline_mask].iloc[0:1]
        selected = pd.concat([selected, baseline], ignore_index=True)
    
    # è¿­ä»£é€‰æ‹©èƒ½æœ€å¤§åŒ–å‚æ•°è¦†ç›–ç‡çš„ç»„åˆ
    while len(selected) < max_combinations:
        best_coverage = -1
        best_index = -1
        
        for i, candidate in grouped_ops.iterrows():
            # è·³è¿‡å·²é€‰æ‹©çš„ç»„åˆ
            if candidate["combination"] in selected["combination"].values:
                continue
                
            # ä¸´æ—¶æ·»åŠ å€™é€‰ç»„åˆ
            temp_selected = pd.concat([selected, grouped_ops.iloc[i:i+1]], ignore_index=True)
            
            # è®¡ç®—å½“å‰è¦†ç›–ç‡
            coverage_scores = [
                calculate_coverage(temp_selected, grouped_ops, param) 
                for param in key_params
            ]
            avg_coverage = np.mean(coverage_scores)
            
            # è®°å½•æœ€ä½³å€™é€‰
            if avg_coverage > best_coverage:
                best_coverage = avg_coverage
                best_index = i
        
        # æ·»åŠ æœ€ä½³å€™é€‰
        if best_index != -1:
            selected = pd.concat([selected, grouped_ops.iloc[best_index:best_index+1]], ignore_index=True)
        else:
            break  # æ²¡æœ‰æ›´å¤šç»„åˆå¯ä¾›é€‰æ‹©
    
    return selected

def plot_radar_diverse_combinations(df: pd.DataFrame, plot_dir: str, max_combinations: int = 16) -> None:
    """
    ç”Ÿæˆé›·è¾¾å›¾ï¼Œå±•ç¤ºæœ€å¤š16ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„æ“ä½œç»„åˆï¼Œæ¯ä¸ªç»„åˆåŒ…å«MSEã€MAEã€SMAPEä¸‰æ¡æŒ‡æ ‡çº¿
    
    å‚æ•°:
        df: åŒ…å«æ‰€æœ‰å®éªŒæ•°æ®çš„DataFrame
        plot_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
        max_combinations: æœ€å¤§å±•ç¤ºçš„ç»„åˆæ•°é‡ï¼Œé»˜è®¤16
    """
    print("\nğŸ“Š ç”Ÿæˆ16ä¸ªä»£è¡¨æ€§ç»„åˆçš„MSEã€MAEã€SMAPEé›·è¾¾å¯¹æ¯”å›¾...")
    try:
        # 1. é€‰æ‹©æœ€å…·å¤šæ ·æ€§çš„ç»„åˆ
        combinations = get_diverse_combinations(df, max_combinations)
        num_combinations = len(combinations)
        print(f"ğŸ“Œ å±•ç¤º{num_combinations}ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„æ“ä½œç»„åˆ")
        
        # 2. å‡†å¤‡é›·è¾¾å›¾æ•°æ®
        metrics = ["mse", "mae", "smape"]
        metric_labels = ["MSE", "MAE", "SMAPE (%)"]
        num_metrics = len(metrics)
        
        # æ•°æ®æ ‡å‡†åŒ–ï¼ˆä½¿ç”¨æ‰€æœ‰ç»„åˆçš„æœ€å¤§å€¼è¿›è¡Œæ ‡å‡†åŒ–ï¼‰
        all_groups = df.groupby("combination").agg({
            "mse": "mean",
            "mae": "mean",
            "smape": "mean"
        }).reset_index()
        
        max_values = {
            "mse": all_groups["mse"].max(),
            "mae": all_groups["mae"].max(),
            "smape": all_groups["smape"].max()
        }
        
        def normalize(value, metric):
            """å°†å€¼æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´ï¼ˆå€¼è¶Šå°è¶Šå¥½ï¼‰"""
            return value / max_values[metric] if max_values[metric] != 0 else 0
        
        # 3. ç»˜åˆ¶é›·è¾¾å›¾
        angles = [n / float(num_metrics) * 2 * pi for n in range(num_metrics)]
        angles += [angles[0]]  # é—­åˆå›¾å½¢
        metric_labels += [metric_labels[0]]  # é—­åˆæ ‡ç­¾
        
        # åˆ›å»ºç”»å¸ƒ
        fig, ax = plt.subplots(figsize=(14, 14), subplot_kw=dict(polar=True))
        
        # ä¸ºä¸åŒæŒ‡æ ‡å®šä¹‰é¢œè‰²å’Œæ ·å¼
        metric_styles = {
            "mse": {"color": "#2196F3", "marker": "o", "linewidth": 1.5},    # è“è‰²
            "mae": {"color": "#4CAF50", "marker": "s", "linewidth": 1.5},    # ç»¿è‰²
            "smape": {"color": "#FF9800", "marker": "^", "linewidth": 1.5}   # æ©™è‰²
        }
        
        # ä¸ºæ¯ä¸ªç»„åˆç»˜åˆ¶ä¸‰æ¡æŒ‡æ ‡çº¿
        for _, row in combinations.iterrows():
            combo_name = row["combination"]
            
            for metric in metrics:
                # å‡†å¤‡è¯¥æŒ‡æ ‡çš„æ•°æ®
                values = [0 if metric != m else normalize(row[metric], metric) for m in metrics]
                values += [values[0]]  # é—­åˆå›¾å½¢
                
                # åªåœ¨ç¬¬ä¸€ä¸ªç»„åˆæ·»åŠ å›¾ä¾‹
                label = metric_labels[metrics.index(metric)] if combo_name == combinations.iloc[0]["combination"] else ""
                ax.plot(angles, values, 
                        color=metric_styles[metric]["color"],
                        marker=metric_styles[metric]["marker"],
                        linewidth=metric_styles[metric]["linewidth"],
                        alpha=0.7, label=label)
        
        # æ·»åŠ æ ‡ç­¾
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metric_labels[:-1], size=12)
        
        # æ·»åŠ å›¾ä¾‹
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11,
                 title="Metrics", title_fontsize=13)
        
        # ä¼˜åŒ–ç»„åˆåç§°æ˜¾ç¤ºï¼ˆåˆ†ä¸¤åˆ—æ”¾ç½®ä»¥é¿å…é‡å ï¼‰
        radius = ax.get_ylim()[1] * 1.05
        for i, row in combinations.iterrows():
            # å¶æ•°è¡Œæ”¾å³ä¾§ï¼Œå¥‡æ•°è¡Œæ”¾å·¦ä¾§
            angle = angles[1] if i % 2 == 0 else angles[1] + pi
            x = radius * np.cos(angle)
            y = radius * np.sin(angle)
            
            # æ–‡æœ¬æ—‹è½¬è§’åº¦ä¸æ”¾ç½®ä½ç½®åŒ¹é…
            rotation = 0 if i % 2 == 0 else 180
            ha = 'left' if i % 2 == 0 else 'right'
            
            ax.text(x, y + (i//2)*0.1, row["combination"], 
                    ha=ha, va='center', rotation=rotation, 
                    fontsize=9, alpha=0.8)
        
        # æ·»åŠ æ ‡é¢˜
        ax.set_title(f"Diverse Operation Combinations Performance Comparison ({num_combinations} combinations)", 
                    size=16, pad=20)
        
        # è®¾ç½®å¾„å‘è½´èŒƒå›´
        ax.set_ylim(0, 1.1)
        
        # æ·»åŠ ç½‘æ ¼çº¿ä½¿é˜…è¯»æ›´æ–¹ä¾¿
        ax.grid(True, alpha=0.3)
        
        # ä¿å­˜å›¾ç‰‡
        save_path = os.path.join(plot_dir, f"radar_diverse_{num_combinations}_combinations.png")
        plt.tight_layout()
        plt.savefig(save_path, bbox_inches="tight", dpi=300)
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆé›·è¾¾å›¾å¤±è´¥ï¼š{str(e)}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from math import pi

def get_16_combinations(df: pd.DataFrame) -> pd.DataFrame:
    """è·å–16ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„ç»„åˆï¼ˆç¡®ä¿è¦†ç›–ä¸åŒç±»å‹ï¼‰"""
    # åˆ›å»ºç»„åˆæ ‡è¯†
    df["combination"] = df.apply(
        lambda x: f"{x['denoiser_method']}+{x['normalizer_method']}+{x['warper_method']}+{x['trimmer_seq_len']}",
        axis=1
    )
    
    # æŒ‰ç»„åˆåˆ†ç»„è®¡ç®—å„æŒ‡æ ‡å¹³å‡å€¼
    grouped_ops = df.groupby("combination").agg({
        "mse": "mean",
        "mae": "mean",
        "smape": "mean"
    }).reset_index()
    
    # ç¡®ä¿æˆ‘ä»¬æœ‰æ­£å¥½16ä¸ªç»„åˆï¼ˆå¦‚æœä¸è¶³åˆ™å…¨éƒ¨ä½¿ç”¨ï¼Œå¦‚æœè¿‡å¤šåˆ™é‡‡æ ·ï¼‰
    if len(grouped_ops) <= 16:
        return grouped_ops
    else:
        # æŒ‰MSEæ’åºåå‡åŒ€é‡‡æ ·16ä¸ªï¼Œç¡®ä¿è¦†ç›–ä¸åŒæ€§èƒ½åŒºé—´
        grouped_ops = grouped_ops.sort_values("mse")
        indices = np.linspace(0, len(grouped_ops)-1, 16, dtype=int)
        return grouped_ops.iloc[indices]

def plot_three_lines_radar(df: pd.DataFrame, plot_dir: str) -> None:
    """
    ç”Ÿæˆé›·è¾¾å›¾ï¼ŒåŒ…å«ä¸‰æ¡çº¿ï¼ˆMSEã€MAEã€SMAPEï¼‰ï¼Œæ¯æ¡çº¿ä¸Šæœ‰16ä¸ªç‚¹ä»£è¡¨16ä¸ªç»„åˆ
    
    å‚æ•°:
        df: åŒ…å«æ‰€æœ‰å®éªŒæ•°æ®çš„DataFrame
        plot_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
    """
    print("\nğŸ“Š ç”Ÿæˆä¸‰æ¡çº¿ï¼ˆMSEã€MAEã€SMAPEï¼‰å„16ä¸ªç‚¹çš„é›·è¾¾å›¾...")
    try:
        # 1. è·å–16ä¸ªç»„åˆ
        combinations = get_16_combinations(df)
        num_combinations = len(combinations)
        print(f"ğŸ“Œ å±•ç¤º{num_combinations}ä¸ªç»„åˆï¼Œæ¯æ¡æŒ‡æ ‡çº¿æœ‰{num_combinations}ä¸ªç‚¹")
        
        # 2. å‡†å¤‡é›·è¾¾å›¾æ•°æ®
        metrics = ["mse", "mae", "smape"]
        metric_labels = ["MSE", "MAE", "SMAPE (%)"]
        
        # ä¸ºæ¯ä¸ªæŒ‡æ ‡å•ç‹¬æ ‡å‡†åŒ–ï¼ˆåŒä¸€æŒ‡æ ‡å†…çš„ç»„åˆæ¯”è¾ƒï¼‰
        metric_scalers = {}
        for metric in metrics:
            # ä½¿ç”¨è¯¥æŒ‡æ ‡çš„æœ€å¤§å€¼è¿›è¡Œæ ‡å‡†åŒ–
            max_val = combinations[metric].max()
            min_val = combinations[metric].min()
            metric_scalers[metric] = {"max": max_val, "min": min_val}
        
        def normalize(value, metric):
            """å°†å€¼æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´ï¼ˆå€¼è¶Šå°è¶Šå¥½ï¼‰"""
            scaler = metric_scalers[metric]
            range_val = scaler["max"] - scaler["min"]
            return (value - scaler["min"]) / range_val if range_val != 0 else 0
        
        # 3. ç»˜åˆ¶é›·è¾¾å›¾
        # è®¡ç®—è§’åº¦ï¼ˆ16ä¸ªç‚¹ + é—­åˆç‚¹ï¼‰
        num_points = num_combinations
        angles = [n / float(num_points) * 2 * pi for n in range(num_points)]
        angles += [angles[0]]  # é—­åˆå›¾å½¢
        
        # åˆ›å»ºç”»å¸ƒ
        fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))
        
        # ä¸ºä¸åŒæŒ‡æ ‡å®šä¹‰æ ·å¼
        metric_styles = {
            "mse": {"color": "#2196F3", "marker": "o", "linewidth": 2, "label": "MSE"},
            "mae": {"color": "#4CAF50", "marker": "s", "linewidth": 2, "label": "MAE"},
            "smape": {"color": "#FF9800", "marker": "^", "linewidth": 2, "label": "SMAPE"}
        }
        
        # ä¸ºæ¯ä¸ªæŒ‡æ ‡ç»˜åˆ¶ä¸€æ¡çº¿ï¼Œçº¿ä¸Šæœ‰16ä¸ªç‚¹ï¼ˆæ¯ä¸ªç»„åˆä¸€ä¸ªç‚¹ï¼‰
        for metric in metrics:
            # å‡†å¤‡è¯¥æŒ‡æ ‡çš„16ä¸ªç‚¹æ•°æ®
            values = [normalize(combinations.iloc[i][metric], metric) for i in range(num_points)]
            values += [values[0]]  # é—­åˆå›¾å½¢
            
            # ç»˜åˆ¶çº¿
            style = metric_styles[metric]
            ax.plot(angles, values, 
                    color=style["color"],
                    marker=style["marker"],
                    linewidth=style["linewidth"],
                    label=style["label"],
                    alpha=0.8)
        
        # æ·»åŠ ç»„åˆæ ‡ç­¾ï¼ˆ16ä¸ªç‚¹çš„æ ‡ç­¾ï¼‰
        ax.set_xticks(angles[:-1])  # æ’é™¤æœ€åä¸€ä¸ªé—­åˆç‚¹
        ax.set_xticklabels(combinations["combination"], size=8, rotation=0)
        
        # æ·»åŠ å›¾ä¾‹
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)
        
        # æ·»åŠ æ ‡é¢˜
        ax.set_title(f"Performance Metrics Across 16 Operation Combinations", 
                    size=14, pad=20)
        
        # è®¾ç½®å¾„å‘è½´èŒƒå›´ï¼ˆ0è¡¨ç¤ºè¯¥æŒ‡æ ‡æœ€ä½³ï¼Œ1è¡¨ç¤ºè¯¥æŒ‡æ ‡æœ€å·®ï¼‰
        ax.set_ylim(0, 1.1)
        
        # æ·»åŠ ç½‘æ ¼çº¿
        ax.grid(True, alpha=0.3)
        
        # è°ƒæ•´æ ‡ç­¾è§’åº¦ä»¥é¿å…é‡å 
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
        
        # ä¿å­˜å›¾ç‰‡
        save_path = os.path.join(plot_dir, "radar_three_lines_16_points.png")
        plt.tight_layout()
        plt.savefig(save_path, bbox_inches="tight", dpi=300)
        plt.close()
        
        print(f"âœ… å·²ä¿å­˜ï¼š{os.path.basename(save_path)}")
    
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆé›·è¾¾å›¾å¤±è´¥ï¼š{str(e)}")


# --------------------------
# ä¸»å‡½æ•°ï¼šæµç¨‹æ§åˆ¶ï¼ˆä¸²è”æ‰€æœ‰æ¨¡å—ï¼‰
# --------------------------
def main():
    # 1. æ¬¢è¿ä¿¡æ¯
    print("=" * 80)
    print("                Preprocessing Parameter Analysis Tool")
    print("=" * 80)
    print("åŠŸèƒ½è¯´æ˜ï¼š")
    print("1. ä»æ§åˆ¶å°è¾“å…¥CSVè·¯å¾„ï¼ˆè‡ªåŠ¨éªŒè¯æœ‰æ•ˆæ€§ï¼‰")
    print("2. åœ¨CSVåŒçº§ç›®å½•åˆ›å»ºå›¾ç‰‡æ–‡ä»¶å¤¹ï¼ˆæ— å¼¹çª—ï¼Œä»…ä¿å­˜æ–‡ä»¶ï¼‰")
    print("3. ç”Ÿæˆ6ç±»åˆ†æå›¾ï¼šTop Nç»„åˆã€å‚æ•°å½±å“ã€äº¤äº’çƒ­åŠ›å›¾ç­‰")
    print("4. è¾“å‡ºæœ€ä¼˜é¢„å¤„ç†ç»„åˆæ±‡æ€»ï¼Œè¾…åŠ©å‚æ•°é€‰æ‹©")
    print("=" * 80)
    
    # 2. è·å–æœ‰æ•ˆCSVè·¯å¾„
    csv_path = get_valid_csv_path()
    
    # 3. åˆ›å»ºå›¾ç‰‡æ–‡ä»¶å¤¹
    plot_dir = create_plot_dir(csv_path)
    
    # 4. åŠ è½½è§£ææ•°æ®
    df = load_parse_data(csv_path)
    df = df[df["mse"] <= max_mse].copy()
    # 5. ç”ŸæˆTop Næœ€ä¼˜ç»„åˆå›¾
    plot_top_performers(df, plot_dir, metric="mse", top_n=10)
    
    # 6. ç”Ÿæˆå•ä¸ªå‚æ•°å½±å“å›¾ï¼ˆå¯æ ¹æ®å®é™…å‚æ•°è°ƒæ•´åˆ—è¡¨ï¼‰
    key_params = ["trimmer_seq_len", "normalizer_method", "denoiser_method", "sampler_factor"]
    for param in key_params:
        plot_single_param_impact(df, plot_dir, param, metric="mse")
    
    # 7. ç”Ÿæˆå‚æ•°äº¤äº’å›¾ï¼ˆé€‰æ‹©å…³é”®å‚æ•°å¯¹ï¼‰
    plot_param_interaction(df, plot_dir, "trimmer_seq_len", "normalizer_method", metric="mse")
    plot_param_interaction(df, plot_dir, "normalizer_method", "denoiser_method", metric="mse")
    
    # 8. ç”ŸæˆæŒ‡æ ‡ç›¸å…³æ€§çŸ©é˜µå›¾
    plot_metric_corr(df, plot_dir)

    plot_operation_vs_baseline(df, plot_dir, metric="mse")
    plot_operation_vs_baseline(df, plot_dir, metric="smape")
    plot_radar_diverse_combinations(df, plot_dir, max_combinations=16)
    plot_three_lines_radar(df, plot_dir)


    # # 9. ç”Ÿæˆæ¨ç†æ—¶é—´ä¸æ€§èƒ½æƒè¡¡å›¾
    # plot_time_vs_metric(df, plot_dir, metric="mse")
    # plot_time_vs_metric(df, plot_dir, metric="smape")  # é¢å¤–ç”ŸæˆSMAPEçš„æƒè¡¡å›¾
    
    # 10. è¾“å‡ºæœ€ä¼˜å‚æ•°æ±‡æ€»
    print_optimal_params(df, metric="mse", top_n=5)
    
    # 11. å®Œæˆæç¤º
    print("\n" + "=" * 80)
    print("åˆ†æå®Œæˆï¼æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜è‡³ï¼š")
    print(f"ğŸ“ {plot_dir}")
    print("=" * 80)


if __name__ == "__main__":
    main()
